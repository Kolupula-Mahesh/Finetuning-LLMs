{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e2872cf09d04389a2d504b74b7bf9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4926122c724424191c35dd3349875eb",
              "IPY_MODEL_ce99d13432b84a3ba8036d1c8bbe6169",
              "IPY_MODEL_3e5a19a9a2a746b5bf9f23c41ee67b27"
            ],
            "layout": "IPY_MODEL_4a6e80f2b7994cbfb7c9224c165388fe"
          }
        },
        "c4926122c724424191c35dd3349875eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cacdedb0e93449b83ef60b335947194",
            "placeholder": "​",
            "style": "IPY_MODEL_738546f26de8491496b499d1c947c240",
            "value": "Map: 100%"
          }
        },
        "ce99d13432b84a3ba8036d1c8bbe6169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39ba15e17474aeea3eb93ade9110979",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e28f9dd738d14b888bf1e67101b83fe3",
            "value": 12
          }
        },
        "3e5a19a9a2a746b5bf9f23c41ee67b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9321823c7c2e4f8586d2b72aa19676bc",
            "placeholder": "​",
            "style": "IPY_MODEL_d6f86d4c7de04409b02567b8058518ae",
            "value": " 12/12 [00:00&lt;00:00, 116.17 examples/s]"
          }
        },
        "4a6e80f2b7994cbfb7c9224c165388fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cacdedb0e93449b83ef60b335947194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738546f26de8491496b499d1c947c240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39ba15e17474aeea3eb93ade9110979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28f9dd738d14b888bf1e67101b83fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9321823c7c2e4f8586d2b72aa19676bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6f86d4c7de04409b02567b8058518ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# How to Fine-Tune GPT-2 for Medical Q&A (CPU-friendly)\n",
        "# ==============================\n",
        "# 0️⃣ Install & imports\n",
        "# (In Colab: this will install required packages. In a local env you might skip install.)\n",
        "!pip install -q transformers datasets\n",
        "\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Force CPU usage (even if a GPU is present; remove this line if you want GPU use)\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "# Device detection\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ Prepare Q&A dataset (supervised)\n",
        "# - We train on Q: <question> A: <answer> lines so the model learns to map questions → answers\n",
        "# - Add or replace these pairs with your own medical Q&A to improve accuracy\n",
        "# ==============================\n",
        "qa_pairs = [\n",
        "    {\"q\": \"What are the main types of cardiovascular diseases?\",\n",
        "     \"a\": \"Coronary artery disease, stroke, heart failure, and hypertension.\"},\n",
        "\n",
        "    {\"q\": \"What are the risk factors for cardiovascular diseases?\",\n",
        "     \"a\": \"High blood pressure, smoking, obesity, diabetes, and high cholesterol.\"},\n",
        "\n",
        "    {\"q\": \"How can cardiovascular diseases be prevented?\",\n",
        "     \"a\": \"Healthy diet, regular exercise, quitting smoking, and controlling blood pressure and cholesterol.\"},\n",
        "\n",
        "    {\"q\": \"What causes diabetes?\",\n",
        "     \"a\": \"Diabetes results from problems with insulin production or insulin use in the body.\"},\n",
        "\n",
        "    {\"q\": \"How can diabetes be managed effectively?\",\n",
        "     \"a\": \"With a balanced diet, regular exercise, medication or insulin, and monitoring blood sugar levels.\"},\n",
        "\n",
        "    {\"q\": \"What are complications of uncontrolled diabetes?\",\n",
        "     \"a\": \"Kidney damage, vision loss, nerve damage, and increased risk of heart disease.\"},\n",
        "\n",
        "    {\"q\": \"What are common symptoms of flu?\",\n",
        "     \"a\": \"Fever, cough, sore throat, body aches, and fatigue.\"},\n",
        "\n",
        "    {\"q\": \"How can flu be prevented?\",\n",
        "     \"a\": \"Seasonal vaccination, hand washing, and avoiding close contact with sick people.\"},\n",
        "\n",
        "    {\"q\": \"How can we improve our immune system naturally?\",\n",
        "     \"a\": \"Eat nutritious food, get regular sleep, exercise, stay hydrated, and manage stress.\"},\n",
        "\n",
        "    {\"q\": \"What vitamins help immunity?\",\n",
        "     \"a\": \"Vitamins C and D and minerals like zinc support immune function.\"},\n",
        "\n",
        "    {\"q\": \"What are common respiratory diseases?\",\n",
        "     \"a\": \"Asthma, chronic obstructive pulmonary disease (COPD), pneumonia, and bronchitis.\"},\n",
        "\n",
        "    {\"q\": \"How to maintain good respiratory health?\",\n",
        "     \"a\": \"Avoid smoking, reduce pollution exposure, get vaccinations, and seek prompt care for infections.\"}\n",
        "]\n",
        "\n",
        "# Convert to HF Dataset format: each example is a single text string \"Q: ... A: ...\"\n",
        "train_texts = [{\"text\": f\"Q: {item['q']} A: {item['a']}\"} for item in qa_pairs]\n",
        "dataset = Dataset.from_list(train_texts)\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ Load GPT-2 tokenizer & model (small GPT-2)\n",
        "# - Using GPT-2 (small) to keep runtime low on CPU\n",
        "# ==============================\n",
        "model_name = \"gpt2\"  # small GPT-2\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "# GPT-2 has no pad token by default — set pad_token to eos\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ Tokenize dataset\n",
        "# - We set a comfortable max_length (128). For longer Q/A, increase this.\n",
        "# ==============================\n",
        "def tokenize_fn(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "tokenized = dataset.map(tokenize_fn, batched=True)\n",
        "tokenized = tokenized.remove_columns([c for c in tokenized.column_names if c not in (\"input_ids\",\"attention_mask\")])\n",
        "tokenized.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\"])\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ Training arguments (CPU-friendly)\n",
        "# - Small batch size and modest epochs for CPU runs\n",
        "# ==============================\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-medical-qa-cpu\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=4,                # increase epochs if you have more data\n",
        "    per_device_train_batch_size=1,     # keep 1 on CPU\n",
        "    gradient_accumulation_steps=1,     # increase to simulate larger batch if desired\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    save_steps=50,\n",
        "    save_total_limit=2,\n",
        "    fp16=False,                        # disabled for CPU\n",
        "    report_to=[]                       # disable wandb/other logging integrations\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ Data collator\n",
        "# - Simple collator that returns input_ids, attention_mask and labels (labels = input_ids for causal LM)\n",
        "# ==============================\n",
        "def data_collator(batch):\n",
        "    return {\n",
        "        \"input_ids\": torch.stack([b[\"input_ids\"] for b in batch]),\n",
        "        \"attention_mask\": torch.stack([b[\"attention_mask\"] for b in batch]),\n",
        "        \"labels\": torch.stack([b[\"input_ids\"] for b in batch])\n",
        "    }\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ Trainer setup\n",
        "# ==============================\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 7️⃣ Fine-tune the model (this will run on CPU)\n",
        "# - Training time depends on number of epochs and dataset size; be patient on CPU.\n",
        "# ==============================\n",
        "trainer.train()\n",
        "\n",
        "# ==============================\n",
        "# 8️⃣ Save the fine-tuned model and tokenizer\n",
        "# ==============================\n",
        "trainer.save_model(\"./gpt2-medical-qa-cpu\")\n",
        "tokenizer.save_pretrained(\"./gpt2-medical-qa-cpu\")\n",
        "\n",
        "# Optionally reload (verifies save)\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-medical-qa-cpu\").to(device)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-medical-qa-cpu\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# ==============================\n",
        "# 9️⃣ Inference: generate answers (deterministic beam search)\n",
        "# - We use the \"Q: ... A:\" prompt format the model was trained on.\n",
        "# - Beam search (do_sample=False, num_beams>1) gives more stable factual outputs.\n",
        "# - We also post-process to remove repeated question text and tidy whitespace.\n",
        "# ==============================\n",
        "def ask_question(question, max_length=80):\n",
        "    prompt = f\"Q: {question} A:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    out = model.generate(\n",
        "        **inputs,\n",
        "        max_length=max_length,\n",
        "        do_sample=False,          # deterministic decoding\n",
        "        num_beams=4,              # beam size — higher = more compute but often more accurate\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    decoded = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "    # Keep only text after \"A:\" and remove any repeated question text\n",
        "    if \"A:\" in decoded:\n",
        "        decoded = decoded.split(\"A:\",1)[1]\n",
        "    decoded = re.sub(re.escape(question), \"\", decoded, flags=re.IGNORECASE)\n",
        "    decoded = re.sub(r\"\\n+\", \" \", decoded)\n",
        "    decoded = re.sub(r\"\\s{2,}\", \" \", decoded).strip()\n",
        "    return decoded\n",
        "\n",
        "# ==============================\n",
        "# 10️⃣ Test sample questions (prints Q / A pairs cleanly)\n",
        "# ==============================\n",
        "test_questions = [\n",
        "    \"What are the risk factors for cardiovascular diseases?\",\n",
        "    \"How can diabetes be managed effectively?\",\n",
        "    \"What are the common symptoms of flu?\",\n",
        "    \"How can we improve our immune system naturally?\",\n",
        "    \"What are common respiratory diseases?\"\n",
        "]\n",
        "\n",
        "for i, q in enumerate(test_questions, 1):\n",
        "    print(f\"Q{i}: {q}\")\n",
        "    print(f\"A{i}: {ask_question(q)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617,
          "referenced_widgets": [
            "5e2872cf09d04389a2d504b74b7bf9e9",
            "c4926122c724424191c35dd3349875eb",
            "ce99d13432b84a3ba8036d1c8bbe6169",
            "3e5a19a9a2a746b5bf9f23c41ee67b27",
            "4a6e80f2b7994cbfb7c9224c165388fe",
            "9cacdedb0e93449b83ef60b335947194",
            "738546f26de8491496b499d1c947c240",
            "b39ba15e17474aeea3eb93ade9110979",
            "e28f9dd738d14b888bf1e67101b83fe3",
            "9321823c7c2e4f8586d2b72aa19676bc",
            "d6f86d4c7de04409b02567b8058518ae"
          ]
        },
        "id": "SVd07CF2SUnQ",
        "outputId": "a1f85208-2e19-4540-95d6-fa9651ad8c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e2872cf09d04389a2d504b74b7bf9e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-815771240.py:125: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [48/48 03:22, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.478100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.331300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.296100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: What are the risk factors for cardiovascular diseases?\n",
            "A1: High blood pressure, smoking, high cholesterol, diabetes, heart disease, and hypertension.\n",
            "\n",
            "Q2: How can diabetes be managed effectively?\n",
            "A2: Diabetes is caused by insulin deficiency, insulin resistance, high blood pressure, and high cholesterol.\n",
            "\n",
            "Q3: What are the common symptoms of flu?\n",
            "A3: Fever, cough, sore throat, and body aches.\n",
            "\n",
            "Q4: How can we improve our immune system naturally?\n",
            "A4: Healthy diet, regular exercise, and regular blood pressure control.\n",
            "\n",
            "Q5: What are common respiratory diseases?\n",
            "A5: Chronic obstructive pulmonary disease (COPD), pneumonia, and bronchitis.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KR8_gpjmSYu9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}